{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from crawler_llama_index.ingest import Parser, ParseRecord\n",
    "\n",
    "class thisParser(Parser):\n",
    "    def parse(self, url, html) -> ParseRecord:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        main_tag = soup.find('main', {'property': 'mainContentOfPage'})\n",
    "        if main_tag:\n",
    "            content = main_tag.get_text(separator=' ')\n",
    "        else:\n",
    "            content = None\n",
    "            \n",
    "        title = soup.title.string if soup.title else \"\"\n",
    "    \n",
    "        return ParseRecord(url=url, title=title, content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"IRCC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler_llama_index.crawler import Crawler\n",
    "\n",
    "crawl_queue = []\n",
    "\n",
    "crawler = Crawler(name=name, seed=\"https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/works.html\", \n",
    "                      wait=2,\n",
    "                      to_be_crawled=lambda u: u.startswith(\"https://www.canada.ca/en/immigration-refugees-citizenship/\"),\n",
    "                      crawl_queue = crawl_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler_llama_index.ingest import Ingestor, CrawlReader\n",
    "\n",
    "crawl_reader = CrawlReader(crawl_queue=crawl_queue, parser=thisParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestor = Ingestor(reader=crawl_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "crawler.logger.setLevel(logging.INFO)\n",
    "ingestor.logger.setLevel(logging.DEBUG)\n",
    "crawl_reader.logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler.start()\n",
    "\n",
    "#crawler.join()\n",
    "while len(crawl_queue) < 2000:\n",
    "    time.sleep(0.1)\n",
    "        \n",
    "crawler.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler_llama_index.index import Indexer\n",
    "indexer = Indexer(name=name, data_loader=ingestor)\n",
    "indexer.logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:40:19.653 [WARNING ]               py.warnings - /home/behnam/venv/omniscient/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "09:40:19.851 [INFO    ] sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "09:40:19.853 [DEBUG   ]    urllib3.connectionpool - Starting new HTTPS connection (1): huggingface.co:443\n",
      "09:40:19.981 [DEBUG   ]    urllib3.connectionpool - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/modules.json HTTP/1.1\" 200 0\n",
      "09:40:20.027 [DEBUG   ]    urllib3.connectionpool - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "09:40:20.078 [DEBUG   ]    urllib3.connectionpool - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "09:40:20.119 [DEBUG   ]    urllib3.connectionpool - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/modules.json HTTP/1.1\" 200 0\n",
      "09:40:20.161 [DEBUG   ]    urllib3.connectionpool - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "09:40:20.206 [DEBUG   ]    urllib3.connectionpool - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "09:40:21.053 [DEBUG   ]    urllib3.connectionpool - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "09:40:21.168 [DEBUG   ]    urllib3.connectionpool - https://huggingface.co:443 \"GET /api/models/BAAI/bge-large-en-v1.5/revision/main HTTP/1.1\" 200 146953\n",
      "09:40:21.353 [INFO    ] sentence_transformers.SentenceTransformer - Use pytorch device_name: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:40:22.662 [INFO    ]                   Indexer - try to load index\n",
      "09:40:22.662 [DEBUG   ] llama_index.storage.kvstore.simple_kvstore - Loading llama_index.storage.kvstore.simple_kvstore from /home/behnam/workspace/omniscient/data/index/IRCC/docstore.json.\n",
      "09:40:22.663 [DEBUG   ]              fsspec.local - open file: /home/behnam/workspace/omniscient/data/index/IRCC/docstore.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/behnam/workspace/omniscient/data/index/IRCC/docstore.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:40:25.651 [DEBUG   ] llama_index.storage.kvstore.simple_kvstore - Loading llama_index.storage.kvstore.simple_kvstore from /home/behnam/workspace/omniscient/data/index/IRCC/index_store.json.\n",
      "09:40:25.652 [DEBUG   ]              fsspec.local - open file: /home/behnam/workspace/omniscient/data/index/IRCC/index_store.json\n",
      "09:40:25.673 [DEBUG   ] llama_index.graph_stores.simple - Loading llama_index.graph_stores.simple from /home/behnam/workspace/omniscient/data/index/IRCC/graph_store.json.\n",
      "09:40:25.674 [DEBUG   ]              fsspec.local - open file: /home/behnam/workspace/omniscient/data/index/IRCC/graph_store.json\n",
      "09:40:25.676 [DEBUG   ] llama_index.vector_stores.simple - Loading llama_index.vector_stores.simple from /home/behnam/workspace/omniscient/data/index/IRCC/image__vector_store.json.\n",
      "09:40:25.676 [DEBUG   ]              fsspec.local - open file: /home/behnam/workspace/omniscient/data/index/IRCC/image__vector_store.json\n",
      "09:40:25.677 [DEBUG   ] llama_index.vector_stores.simple - Loading llama_index.vector_stores.simple from /home/behnam/workspace/omniscient/data/index/IRCC/default__vector_store.json.\n",
      "09:40:25.677 [DEBUG   ]              fsspec.local - open file: /home/behnam/workspace/omniscient/data/index/IRCC/default__vector_store.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/behnam/workspace/omniscient/data/index/IRCC/index_store.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:45:57.814 [INFO    ] llama_index.indices.loading - Loading all indices.\n",
      "09:45:59.536 [INFO    ]                   Indexer - number of docs = 95234\n",
      "09:45:59.536 [INFO    ]                   Indexer - finish loading index\n"
     ]
    }
   ],
   "source": [
    "from crawler_llama_index.index import Indexer\n",
    "import logging\n",
    "\n",
    "indexer = Indexer(name=name)\n",
    "indexer.logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "09:46:09.544 [DEBUG   ] llama_index.indices.utils - > Top 2 nodes:\n",
      "> [Node 4e22c360-c730-48e8-be7f-fe8cbc408e26] [Similarity score:             0.800698] Express Entry is an application management system for the Federal Skilled Workers Program, the Fe...\n",
      "> [Node a85f42f1-0fab-4f34-8c7a-c44155eae834] [Similarity score:             0.792029] \n",
      " \n",
      " \n",
      "How Express Entry works \n",
      " \n",
      " \n",
      " Express Entry is an online system that we use to manage immigr...\n",
      "09:46:09.546 [INFO    ]                   Indexer - response = Context information is below.\n",
      "---------------------\n",
      "title: Express Entry Reports and Publications - Canada.ca\n",
      "\n",
      "Express Entry is an application management system for the Federal Skilled Workers Program, the Federal Skilled Trades Program, the Canadian Experience Class and a portion of the Provincial Nominee Program.\n",
      "\n",
      "title: How Express Entry works - Canada.ca\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "How Express Entry works \n",
      " \n",
      " \n",
      " Express Entry is an online system that we use to manage immigration applications from  skilled workers.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: What is express entry?\n",
      "Answer: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer.query(\"What is express entry?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omniscient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
